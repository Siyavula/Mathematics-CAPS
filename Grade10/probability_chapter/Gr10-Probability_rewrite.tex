\documentclass[a4paper,11pt]{report}

\usepackage{amsmath}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}

\def\complement#1{#1'}

\usepackage{tikz, ifthen}
\usetikzlibrary{arrows,shapes,backgrounds,patterns,decorations.pathreplacing,decorations.pathmorphing}

\input{makedice}

% FHSST definitions
\def\Definition#1#2{\paragraph{Definition:} #1 --- #2}
\newenvironment{wex}[3]%
{\textbf{Worked example:} #1 \\
\textbf{Question:} #2 \\
\textbf{Solution:} #3}%
{}
\newcommand{\westep}[1]{\paragraph{Step:} #1}

\setlength\parindent{0pt}
\setlength\parskip{0.5\baselineskip}
\setlength\textwidth{15cm}
\setlength\textheight{23cm}
\setlength\oddsidemargin{0.5cm}
\setlength\topmargin{0cm}

\begin{document}
\chapter{Probability}

\section{Introduction}
We use probability to describe uncertain events. When you accidentally
drop a slice of bread, you don't know if it's going to fall with the
buttered side facing upwards or downwards. When your favourite sports
team plays a game, you don't know whether they will win or not. When
the weatherman says that there is a 40\% chance of rain tomorrow, you
may or may not end up getting wet.  Uncertainty presents itself to
some degree in every event that occurs around us and in every decision
that we make.

We will see in this chapter that all of these uncertainties can be
described using the rules of probability theory and that we can make
definite conclusions about uncertain processes.

\section{Definitions}
We'll use three examples of uncertain processes to help you understand
the meanings of the different words used in probablity theory: tossing
a coin, rolling dice, a soccer match.

\Definition{Experiment}{An experiment refers to an uncertain process.}

\paragraph{Experiment 1} A coin is tossed and it lands with either heads
(H) or tails (T) facing upwards.

\def\coinheads{\draw (0,0) circle (1cm); \draw (0,0) circle (0.8cm); \draw (0,0) node {\Huge\textbf{H}};}
\def\cointails{\draw (0,0) circle (1cm); \draw (0,0) circle (0.8cm); \draw (0,0) node {\Huge\textbf{T}};}

\begin{center}\begin{tikzpicture}\coinheads\end{tikzpicture}\end{center}

\paragraph{Experiment 2} Two dice are rolled and the total number of dots
added up.

\begin{center}
  \begin{tikzpicture}
    \makedie{3}{shift={(-1,0)},rotate=10}
    \makedie{5}{shift={(1,0)},rotate=-20}
  \end{tikzpicture}
\end{center}

\paragraph{Experiment 3} Two teams play in a soccer match and we are
interested in the final score.

\begin{center}
  \textbf{FIGURE: soccer score board}
\end{center}

\Definition{Outcome}{An {\em outcome} of an experiment is a single
  result of that experiment.}

Each of the figures for the experiments described above shows one
possible outcome.

\Definition{Sample space}{The {\em sample space} of an experiment is
  the set of all possible outcomes of that experiment. The sample
  space is denoted with the symbol \(S\) and the size of the sample
  space (the total number of possible outcomes) is denoted with
  \(n(S)\).}

Even though we are usually interested in the outcome of an experiment,
we also need to know what the other outcomes could have been. Let's
have a look at the sample spaces of each of our three experiments.

\paragraph{Experiment 1} Since a coin can land in one of only two ways
(we will ignore the possibility that the coin lands on its edge), the
sample space is the set \(S=\{\textrm{H}, \textrm{T}\}\). The size of the sample space
is \(n(S)=2\).

\begin{center}
  \begin{tikzpicture}
    \begin{scope}[xshift=-1.5cm]
      \coinheads
    \end{scope}
    \begin{scope}[xshift=+1.5cm]
      \cointails
    \end{scope}
    \draw (-3, -1.5) rectangle (3, 1.5) node[anchor=south east] {$S$};
  \end{tikzpicture}
\end{center}

\paragraph{Experiment 2} Each of the dice can land on a number from 1
to 6. In this experiment the sample space of all possible outcomes is
every possible combination of the 6 numbers on the first die with the
6 numbers on the second die. This gives a total of \(n(S) = 6 \times 6
= 36\) possible outcomes. The figure below shows all of the outcomes
in the sample space.

\begin{center}
\begin{tikzpicture}
  \begin{scope}[scale=0.5]
  \foreach \x in {1, ..., 6} {
    \foreach \y in {1, ..., 6} {
      \pgfmathparse{15*rand} \let\rot\pgfmathresult
      \makediesmall{\x}{shift={(4cm*\x-0.66cm,-2cm*\y)},rotate=\rot}
      \pgfmathparse{15*rand} \let\rot\pgfmathresult
      \makediesmall{\y}{shift={(4cm*\x+0.66cm,-2cm*\y)},rotate=\rot}
    }
  }
  \draw[thick] (2.5cm-0.66cm, -0.5cm) rectangle (25.5cm+0.66cm, -13.5cm);
  \draw (25.5cm+0.66cm, -0.5cm) node[anchor=south east] {$S$};
  \end{scope}
\end{tikzpicture}
\end{center}

\paragraph{Experiment 3} Each soccer team can get an integer score
from 0 upwards. Usually we don't expect a score to go much higher than
5 goals, but there is no reason why this cannot happen. So the sample
space of this experiment consists of all possible combinations of two
non-negative integers. The figure below shows all of the
possibilities. Since we do not limit the score of a team, this sample
space is infinitely large.

\begin{center}
  \begin{tikzpicture}
    \foreach \x in {0, ..., 3} {
      \foreach \y in {0, ..., 3} {
        \draw (\x*1.5cm,-\y) node {\x\ --\ \y};
      }
    }
    \foreach \x in {0, ..., 2} {
      \draw (\x*1.5cm,-3.67cm) node {$\vdots$};
    }
    \foreach \y in {0, ..., 2} {
      \draw (5.5cm,-\y) node {$\cdots$};
    }
    \draw (5.5cm,-3.67cm) node {$\ddots$};

    \draw[thick] (-0.75cm, -4.17cm) -- (-0.75, 0.5cm) -- (6cm, 0.5cm);
    \draw (6cm, 0.5cm) node[anchor=south east] {$S$};
  \end{tikzpicture}
\end{center}

\Definition{Event}{An {\em event} is a specific set of outcomes of an
  experiment that you are interested in. An event is denoted with the
  letter \(E\) and the number of outcomes in the event with \(n(E)\).}

\paragraph{Experiment 1} Let's say that we would like the coin to land
heads up. Here the event contains a single outcome
\(E=\{\textrm{H}\}\), \(n(E)=1\).

\paragraph{Experiment 2} Let's say that we are interested in the sum
of the dice being 8. In this case the event set is
$E=\{($\raisebox{-2pt}{\begin{tikzpicture}
  \begin{scope}[scale=0.333]
    \makediegeneral{2}{xshift=-0.7cm}{0.175cm*0.333}
    \makediegeneral{6}{xshift=+0.7cm}{0.175cm*0.333}
  \end{scope}
\end{tikzpicture}}$),($\raisebox{-2pt}{\begin{tikzpicture}
  \begin{scope}[scale=0.333]
    \makediegeneral{3}{xshift=-0.7cm}{0.175cm*0.333}
    \makediegeneral{5}{xshift=+0.7cm}{0.175cm*0.333}
  \end{scope}
\end{tikzpicture}}$),($\raisebox{-2pt}{\begin{tikzpicture}
  \begin{scope}[scale=0.333]
    \makediegeneral{4}{xshift=-0.7cm}{0.175cm*0.333}
    \makediegeneral{4}{xshift=+0.7cm}{0.175cm*0.333}
  \end{scope}
\end{tikzpicture}}$),($\raisebox{-2pt}{\begin{tikzpicture}
  \begin{scope}[scale=0.333]
    \makediegeneral{5}{xshift=-0.7cm}{0.175cm*0.333}
    \makediegeneral{3}{xshift=+0.7cm}{0.175cm*0.333}
  \end{scope}
\end{tikzpicture}}$),($\raisebox{-2pt}{\begin{tikzpicture}
  \begin{scope}[scale=0.333]
    \makediegeneral{6}{xshift=-0.7cm}{0.175cm*0.333}
    \makediegeneral{2}{xshift=+0.7cm}{0.175cm*0.333}
  \end{scope}
\end{tikzpicture}}$)\}$
since it contains all of the possible ways to get 8 dots with 2 dice.
The size of the event set is \(n(E)=5\).

%We can also represent this visually by drawing a line around the
%outcomes in which we are interested.
%FIGURE: sample space with closed curve around event set

\paragraph{Experiment 3} We would like to know whether the first team
will win. For this event to happen the first score must be greater
than the second. \(E=\{(1,0),(2,0),(2,1),(3,0),(3,1),(3,2),\ldots\}\).
This event set is infinitely large.

%FIGURE: sample space with open curve around event set

\section{Theoretical probability}
\Definition{Probability}{A {\em probability} is a real number between
  0 and 1 that describes how likely it is that an event will occur.}
\begin{itemize}
\item A probability of 0 means that an event will never occur.
\item A probability of 1 means that an event will always occur.
\item A probability of 0.5 means that an event will occur half the
  time, or 1 time out of every 2.
\end{itemize}

When all of the possible outcomes of an experiment have an equal
chance of occurring, we can compute the exact theoretical probability
of an event. The probability of an event is the ratio between the
number of outcomes in the event set and the number of possible
outcomes in the sample space.
\[P(E) = \frac{n(E)}{n(S)}\]

\begin{wex}{Theoretical probabilities}{
  What is the theoretical probability of each of the events in the
  first two of our three experiments?
}{
  \westep{Write down the size of the sample space}
  \begin{itemize}
  \item[] Experiment 1: $n(S) = 2$
  \item[] Experiment 2: $n(S) = 36$
  \end{itemize}
  
  \westep{Write down the size of the event set}
  \begin{itemize}
  \item[] Experiment 1: $n(E) = 1$
  \item[] Experiment 2: $n(E) = 5$
  \end{itemize}

  \westep{Compute the theoretical probability}
  \begin{itemize}
  \item[] Experiment 1: $P(E) = \frac{n(E)}{n(S)} = \frac{1}{2} = 0.5$
  \item[] Experiment 2: $P(E) = \frac{n(E)}{n(S)} = \frac{5}{36} = 0.13\dot{8}$
  \end{itemize}
}
\end{wex}

Note that we do not consider the theoretical probability of the third
experiment. The third experiment is different from the first two in an
important way, namely that all possible outcomes (all final scores)
are not equally likely. For example, we know that a score of 1--1 is
quite common, while a score of 11--15 is very, very rare. Because all
outcomes are not equally likely, we cannot use the ratio between
\(n(E)\) and \(n(S)\) to compute the theoretical probability of a team
winning. (\textbf{Interesting fact:} the record for most goals score
by both teams in the FIFA World Cup is 12. This was achieved in 1954
in the match between Austria and Switzerland, where the final score
was 7--5.)

\section{Relative Frequency}

\Definition{Relative frequency}{The relative frequency of an event is
  defined as the number of times that the event occurs during
  experimental trials, divided by the total number of trials
  conducted.}

The relative frequency is not a theoretical quantity, but an
experimental one. We have to repeat an experiment a number of times
and count how many times the outcome of the experiment is in the event
set. Because it is experimental, it is possible to get a different
relative frequency every time that we repeat an experiment.

\begin{wex}{Relative frequency and theoretical probability}{
  We toss a coin 40 times and observe the outcomes. The results of
  the trails are shown in the table below.

\begin{center}\begin{tabular}{lc@{\hspace{0.25cm}}c@{\hspace{0.25cm}}c@{\hspace{0.25cm}}c@{\hspace{0.25cm}}c@{\hspace{0.25cm}}c@{\hspace{0.25cm}}c@{\hspace{0.25cm}}c@{\hspace{0.25cm}}c@{\hspace{0.25cm}}c}
  \toprule
  trial   &  1 &  2 &  3 &  4 &  5 &  6 &  7 &  8 &  9 & 10 \\
  outcome &  H &  T &  T &  T &  H &  T &  H &  H &  H &  T \\
  \midrule
  trial   & 11 & 12 & 13 & 14 & 15 & 16 & 17 & 18 & 19 & 20 \\
  outcome &  H &  T &  T &  H &  T &  T &  T &  H &  T &  T \\
  \midrule
  trial   & 21 & 22 & 23 & 24 & 25 & 26 & 27 & 28 & 29 & 30 \\
  outcome &  H &  H &  H &  T &  H &  T &  H &  T &  T &  T \\
  \bottomrule
\end{tabular}\end{center}

  What is the relative frequency of observing heads after each trial
  and how does it compare to the theoretical probability of observing
  heads?
}{
  \westep{Count the number of positive outcomes}
  A positive outcome is when the outcome is in our event set. The
  table below shows a running count (after each trial $t$) of how many
  positive outcomes $p$ we have observed. For example, after $t=20$
  trials we have observed heads 8 times and tails 12 times and so the
  positive outcome count is $p=8$.

\begin{center}\begin{tabular}{cc@{\hspace{0.25cm}}c@{\hspace{0.25cm}}c@{\hspace{0.25cm}}c@{\hspace{0.25cm}}c@{\hspace{0.25cm}}c@{\hspace{0.25cm}}c@{\hspace{0.25cm}}c@{\hspace{0.25cm}}c@{\hspace{0.25cm}}c}
  \toprule
  $t$ &  1 &  2 &  3 &  4 &  5 &  6 &  7 &  8 &  9 & 10 \\
  $p$ &  1 &  1 &  1 &  1 &  2 &  2 &  3 &  4 &  5 &  5 \\
  \midrule
  $t$ & 11 & 12 & 13 & 14 & 15 & 16 & 17 & 18 & 19 & 20 \\
  $p$ &  6 &  6 &  6 &  7 &  7 &  7 &  7 &  8 &  8 &  8 \\
  \midrule
  $t$ & 21 & 22 & 23 & 24 & 25 & 26 & 27 & 28 & 29 & 30 \\
  $p$ &  9 & 10 & 11 & 11 & 12 & 12 & 13 & 13 & 13 & 13 \\
  \bottomrule
\end{tabular}\end{center}

  \westep{Compute the relative frequency}
  Since the relative frequency is defined as the ratio between the
  number positive trials and the total number of trials,
  \[f=\frac{p}{t}\]

\begin{center}\begin{tabular}{cc@{\hspace{0.25cm}}c@{\hspace{0.25cm}}c@{\hspace{0.25cm}}c@{\hspace{0.25cm}}c@{\hspace{0.25cm}}c@{\hspace{0.25cm}}c@{\hspace{0.25cm}}c@{\hspace{0.25cm}}c@{\hspace{0.25cm}}c}
  \toprule
  $t$ &  1 &  2 &  3 &  4 &  5 &  6 &  7 &  8 &  9 & 10 \\
  $f$ & 1.00 & 0.50 & 0.33 & 0.25 & 0.40 & 0.33 & 0.43 & 0.50 & 0.56 & 0.50 \\
  \midrule
  $t$ & 11 & 12 & 13 & 14 & 15 & 16 & 17 & 18 & 19 & 20 \\
  $f$ & 0.55 & 0.50 & 0.46 & 0.50 & 0.47 & 0.44 & 0.41 & 0.44 & 0.42 & 0.40 \\
  \midrule
  $t$ & 21 & 22 & 23 & 24 & 25 & 26 & 27 & 28 & 29 & 30 \\
  $f$ & 0.43 & 0.45 & 0.48 & 0.46 & 0.48 & 0.46 & 0.48 & 0.46 & 0.45 & 0.43 \\
  \bottomrule
\end{tabular}\end{center}

From the last entry in this table we can now easily read the relative
frequency after 30 trials, namely $13/30 = 0.43$. The relative
frequency is close to the theoretical probability of 0.5. In general,
the relative frequency of an event gets closer to the theoretical
probability of the event as we perform more trials.

A much better way to summarise the table of relative frequencies is in
a plot. The plot below was generated from the table
of numbers above and shows the relative frequency, $f$, as a function
of the number of trials, $t$. In the beginning (after a small number
of trials) the relative frequency
fluctuates a lot around the theoretical probability at 0.5, which is shown with
a dashed line. As the number of trials increases, the relative
frequency fluctuates less and gets closer to the theoretical
probability.

\begin{center}
\includegraphics[width=0.75\textwidth]{coin_toss_trials.pdf}
\end{center}
}
\end{wex}

\paragraph{Experiment 2} We roll the two dice 100 times and observe
whether the sum of the dice equals 8. It turns out that our event
occurs 15 times during the experiment. From this we can calculate the
relative frequency as
\[\frac{15}{100}=0.15\]
This is close to the theoretical probability, which we compute earlier
as $0.13\dot{8}$.

\paragraph{Experiment 3} While watching 10 soccer games where Team 1
plays against Team 2, we record the following final scores.
\begin{center}
\begin{tabular}{lcccccccccc}
  \toprule
  Trial  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\
  \midrule
  Team 1 & 2 & 0 & 1 & 1 & 1 & 1 & 1 & 0 & 5 & 3 \\
  Team 2 & 0 & 2 & 2 & 2 & 2 & 1 & 1 & 0 & 0 & 0 \\
  \bottomrule
\end{tabular}
\end{center}
We are interested in the event where Team 1 wins. From the table above
we see that this happens 3 times out of 10. This means that the
relative frequency of the event is
\[\frac{3}{10} = 0.3\]

It is important to understand the difference between the theoretical
probability of an event and the observed relative frequency of an
experiment. The theoretical probability is a number that we can
compute if we have enough information about the experiment. If the
each possible outcome in the sample space is equally likely, we can
count the number of outcomes in the event set and the number of
outcomes in the sample space to compute the theoretical probability.

The relative frequency depends on the sequence of outcomes that we
observe while doing a statistical experiment. The relative frequency
can be different every time we redo the experiment. The more trials we
run during an experiment, the closer the observed relative frequency
of an event will get to the theoretical probability of the event.

In some cases, like our Experiment 3, it is difficult or impossible to
compute the theoretical probability of an event. Since we do not know
exactly how likely it is that one soccer team will score goals against
another, we can never compute the theoretical probability of events in
soccer. In such cases we can still use the relative frequency to
estimate the theoretical probability by running experiments and
counting the number of positive outcomes.

\section{Venn diagrams}
A Venn diagram is a tool for showing the relationships between
sets. It is helpful for thinking about probability since we deal with
different sets --- so far we have seen the sample space, $S$, and an
event set, $E$.

Consider two possible events, $A$ and $B$, in a sample space $S$. Below
are the possible ways in which the event sets can overlap, represented
using Venn diagrams. In each Venn diagram a set is represented by a
closed curve: a rectangle for $S$ and circles for each of $A$ and $B$.
The space inside a region represents all of the elements included in a
set, while the space outside a region represents the elements excluded
from a set.

FIGURE VENN 1

\paragraph{Example} We can represent the sample space of two rolled dice
and the events
\begin{itemize}
\item $A:$ The sum of the dice equals 8
\item $B:$ At least one of the dice shows
\raisebox{-2pt}{\begin{tikzpicture}
  \begin{scope}[scale=0.333]
    \makediegeneral{2}{}{0.175cm*0.333}
  \end{scope}
\end{tikzpicture}}
\end{itemize}
as a Venn diagram.

FIGURE VENN DICE: sum=8 and at least one 2

We will see in the following section how Venn diagrams can be used to
represent and prove some theorems about probabilities.

\section{Union and intersection}
The union of two sets, $A$ and $B$, is a new set that contains all of
the elements that are in $A$, or in $B$, or in both of them. The union
is written as $A \cup B$.

The intersection of $A$ and $B$ is a new set that contains all of the
elements that are in both $A$ and $B$. The intersection is written as
$A \cap B$.

The figure below shows the union and intersection of two event sets in
a sample space, using Venn diagrams.

\include{venn_union_intersection}

Notes
\begin{itemize}
\item In the middle column the intersection, $A \cap B$, is empty
  since the two sets do not overlap.
\item In the final column the union, $A \cup B$, is equal to $A$ since
  $B$ is fully contained in $A$.
\item In the final column the intersection, $A \cap B$, is equal to
  $B$ since $B$ is fully contained in $A$.
\end{itemize}

\section{Probability identities}
The first identity states that the probability of observing an outcome
from the whole sample space is 1.
\[P(S)=1\]
In other words, every outcome from an experiment must be in the sample
space, $S$. This follows directly from the definition of {\em sample
  space}, namely that it is the set of all possible outcomes.

The second identity relates the union and intersection of two sets:
\[P(A \cup B) = P(A) + P(B) - P(A \cap B)\]

Refer back to VENN 2 from which you can see this identity by adding
the area of circle A to circle B and subtracting intersection area =>
this gives exactly the union area. The common steps are that adding
\(P(A)\) and \(P(B)\) counts \(P(A \cap B)\) twice, so by subtracting
\(P(A \cap B)\) once we get exactly \(P(A \cup B)\).

Work through it visually work one of the columns

\begin{center}
\begin{tabular}{m{0.5cm}m{1.5cm}m{0.5cm}m{1.5cm}m{0.5cm}m{1.5cm}}
   & $P(A)$ & $+$ & $P(B)$ & $-$ & $P(A \cap B)$ \\
 = & \begin{tikzpicture}
   \begin{scope}[scale=1]
     \draw \samplespace;
     \draw[fill=lightgray] \circlepartiala;
   \end{scope}
\end{tikzpicture} & $+$ & \begin{tikzpicture}
   \begin{scope}[scale=1]
     \draw \samplespace;
     \draw[fill=lightgray] \circlepartialb;
   \end{scope}
\end{tikzpicture} & $-$ & \begin{tikzpicture}
   \begin{scope}[scale=1]
     \draw \samplespace;
     \draw[fill=lightgray] (0.31369, 0.31041) arc (197.38:130.73:0.3cm) arc (39.54:-71.43:0.2cm);
   \end{scope}
\end{tikzpicture} \\
 = & \begin{tikzpicture}
   \begin{scope}[scale=1]
     \draw \samplespace;
     \draw[fill=lightgray] \circlepartiala;
   \end{scope}
\end{tikzpicture} & $+$ & \begin{tikzpicture}
   \begin{scope}[scale=1]
     \draw \samplespace;
     \draw[fill=lightgray] (0.31369, 0.31041) arc (-162.62:130.73:0.3cm) arc (39.54:-71.43:0.2cm);
   \end{scope}
\end{tikzpicture} \\
 = & \begin{tikzpicture}
      \begin{scope}[scale=1]
        \draw \samplespace;
        \draw[fill=lightgray] (0.31369, 0.31041) arc (-162.62:130.73:0.3cm) arc (39.54:288.57:0.2cm);
      \end{scope}
\end{tikzpicture} \\
 = & $P(A \cup B)$ \\
\end{tabular}
\end{center}

\paragraph{Experiment 2} We can related the union, intersection for
this experiment: What is the probability of the sum of two
rolled dice equalling 8 or at least one of the dice showing a 2.
\begin{eqnarray*}
  P(A) &=& 5/36 \\
  P(B) &=& 11/36 \\
  P(A \cap B) &=& 2/36 \\
  P(A \cup B) &=& 14/35
\end{eqnarray*}

\section{Mutually exclusive events}
Two events are called {\em mutually exclusive} if they cannot occur at
the same time. Whenever an outcome of an experiment is in the first
event it can not also be in the second event.

Another way of saying this is that the two event sets, $A$ and $B$,
cannot have any elements in common, or $P(A \cap B) = \emptyset$
(where $\emptyset$ denotes the empty set).

VENN2 middle column shows venn diagrams for mutually exclusive
events. You can see that the intersection has no elements. You can
also see that the union $P(A \cup B) = P(A) + P(B)$. This relationship
is true for mutually exclusive events only.

\paragraph{Example} When rolling 2 dice, show that the following two
events are mutually exclusive:
\begin{itemize}
\item $A:$ The sum of the dice equals 8
\item $B:$ At least one of the dice shows
\raisebox{-2pt}{\begin{tikzpicture}
  \begin{scope}[scale=0.333]
    \makediegeneral{1}{}{0.175cm*0.333}
  \end{scope}
\end{tikzpicture}}
\end{itemize}
Draw the sample space and the two sets. Notice that there are no
elements in common. Therefore the event sets are mutually exclusive.

\section{Complementary events}

\paragraph{Definition} The {\em complement} of a set, $A$, is a
different set that contains all of the elements that are not in
$A$. We write the complement of $A$ as $\complement{A}$, or sometimes
as ``$\textrm{not}(A)$''.

For an experiment with sample space $S$ and an event $A$ we can derive
some identities for complementary events.
\begin{itemize}
\item Since every element in $A$ is not in $\complement{A}$, we know
  that complementary events are mutually exclusive.
  \[A \cap \complement{A} = \emptyset\]
\item Since every element in the sample space is either in $A$ or in
  $\complement{A}$, the union of complementary events covers the
  sample space.
  \[A \cup \complement{A} = S\]
\item From the previous two identities, we also know that the
  probabilities of complementary events sum to 1.
  \[P(A) + P(\complement{A}) = P(A \cup \complement{A}) = P(S) = 1\]
\end{itemize}

EXERCISES (only at end of chapter?)

\end{document}
